Mysqlde WAL机制：

    mySql的InnoDB引擎通过使用redo log的方式将磁盘随机写转换成了顺序写，通过将数据更新记录缓存到内存中的数据页后直接返回操作结果，并且在redo log中记录操作
    在内存不足的时候进行刷脏页（同步操作到磁盘中）来保证执行效率。

什么是脏页：
当内存数据页跟磁盘数据页内容不一致的时候，我们称这个内存页为“脏页”。内存数据写入到磁盘后，内存和磁盘上的数据页的内容就一致了，称为“干净页”。

刷脏页的触发时机：
第一种场景是，粉板满了，记不下了。这时候如果再有人来赊账，掌柜就只得放下手里的活儿，将粉板上的记录擦掉一些，留出空位以便继续记账。当然在擦掉之前，他必须先将正确的账目记录到账本中才行。
这个场景，对应的就是InnoDB的redo log写满了。这时候系统会停止所有更新操作，把checkpoint往前推进，redo log留出空间可以继续写。我在第二讲画了一个redo log的示意图，这里我改成环形，便于大家理解。


checkpoint可不是随便往前修改一下位置就可以的。比如图2中，把checkpoint位置从CP推进到CP’，就需要将两个点之间的日志（浅绿色部分），对应的所有脏页都flush到磁盘上。之后，图中从write pos到CP’之间就是可以再写入的redo log的区域。

第二种场景是，这一天生意太好，要记住的事情太多，掌柜发现自己快记不住了，赶紧找出账本把孔乙己这笔账先加进去。
这种场景，对应的就是系统内存不足。当需要新的内存页，而内存不够用的时候，就要淘汰一些数据页，空出内存给别的数据页使用。如果淘汰的是“脏页”，就要先将脏页写到磁盘。
你一定会说，这时候难道不能直接把内存淘汰掉，下次需要请求的时候，从磁盘读入数据页，然后拿redo log出来应用不就行了？这里其实是从性能考虑的。如果刷脏页一定会写盘，就保证了每个数据页有两种状态：

一种是内存里存在，内存里就肯定是正确的结果，直接返回；
另一种是内存里没有数据，就可以肯定数据文件上是正确的结果，读入内存后返回。
这样的效率最高。
第三种场景是，生意不忙的时候，或者打烊之后。这时候柜台没事，掌柜闲着也是闲着，不如更新账本。
这种场景，对应的就是MySQL认为系统“空闲”的时候。当然，MySQL“这家酒店”的生意好起来可是会很快就能把粉板记满的，所以“掌柜”要合理地安排时间，即使是“生意好”的时候，也要见缝插针地找时间，只要有机会就刷一点“脏页”。

第四种场景是，年底了咸亨酒店要关门几天，需要把账结清一下。这时候掌柜要把所有账都记到账本上，这样过完年重新开张的时候，就能就着账本明确账目情况了。
这种场景，对应的就是MySQL正常关闭的情况。这时候，MySQL会把内存的脏页都flush到磁盘上，这样下次MySQL启动的时候，就可以直接从磁盘上读数据，启动速度会很快。

2：关于唯一索引与普通索引的选择：
    在mysql中唯一索引是不回使用到change buffer的而普通所以会使用的change buffer ，并且唯一索引在数据查询中

什么是change buffer:
    当需要更新一个数据页时，如果数据页在内存中就直接更新，而如果这个数据页还没有在内存中的话，在不影响数据一致性的前提下，InooDB会将这些更新操作缓存在change buffer中，这样就不需要从磁盘中读入这个数据页了。在下次查询需要访问这个数据页的时候，将数据页读入内存，然后执行change buffer中与这个页有关的操作。通过这种方式就能保证这个数据逻辑的正确性。
    需要说明的是，虽然名字叫作change buffer，实际上它是可以持久化的数据。也就是说，change buffer在内存中有拷贝，也会被写入到磁盘上。
    将change buffer中的操作应用到原数据页，得到最新结果的过程称为merge。除了访问这个数据页会触发merge外，系统有后台线程会定期merge。在数据库正常关闭（shutdown）的过程中，也会执行merge操作。
    显然，如果能够将更新操作先记录在change buffer，减少读磁盘，语句的执行速度会得到明显的提升。而且，数据读入内存是需要占用buffer pool的，所以这种方式还能够避免占用内存，提高内存利用率。
    如果所有的更新后面，都马上伴随着对这个记录的查询，那么你应该关闭change buffer。而在其他情况下，change buffer都能提升更新性能。
    在实际使用中，你会发现，普通索引和change buffer的配合使用，对于数据量大的表的更新优化还是很明显的。
    特别地，在使用机械硬盘时，change buffer这个机制的收效是非常显著的。所以，当你有一个类似“历史数据”的库，并且出于成本考虑用的是机械硬盘时，那你应该特别关注这些表里的索引，尽量使用普通索引，然后把change buffer 尽量开大，以确保这个“历史数据”表的数据写入速度。
    change buffer 和 redo log
    理解了change buffer的原理，你可能会联想到我在前面文章中和你介绍过的redo log和WAL。
    在前面文章的评论中，我发现有同学混淆了redo log和change buffer。WAL 提升性能的核心机制，也的确是尽量减少随机读写，这两个概念确实容易混淆。所以，这里我把它们放到了同一个流程里来说明，便于你区分这两个概念。
    总结来说：change buffer是用于优化数据库写的而redo log是尽量减少 磁盘的随机读写的。所以对于写多读少的业务使用change buffer很合适。
    所以推荐尽量使用普通索引！！！
唯一索引为什么不能使用change buffer：
    对于唯一索引来说，所有的更新操作都要先判断这个操作是否违反唯一性约束。比如，要插入(4,400)这个记录，就要先判断现在表中是否已经存在k=4的记录，而这必须要将数据页读入内存才能判断。如果都已经读入到内存了，那直接更新内存会更快，就没必要使用change buffer了。

为什么我们用Delete删除了一般的表数据，但数据表占用的空间并没有减少？

    我们知道Mysql的数据是以B+树组织的，但当我们删除某个记录时只是把某个记录占用的位置标记为可复用，当某新增的记录刚要落在这个位置就可以直接覆盖，我们知道Mysql的数据是分页存储的，当整个页里面的数据都被标记删除那整个页都可以被复用，
    所以真正的原理是虽然表面删了但实际上占的空间没有被释放只是被标记为可复用标记。
    同时我们在进行插入操作的时候也有可能会内存空洞（尤其是在主键索引不连续（不紧凑）的情况）会造成页分裂。
    解决方式：重建表,使用alter table t engine=InnoDB;不过表数据打的时候要注意系统的磁盘IO压力

在MySQL 5.6版本开始引入的Online DDL，对这个操作流程做了优化。

简单描述一下引入了Online DDL之后，重建表的流程：

    建立一个临时文件，扫描表A主键的所有数据页；

    用数据页中表A的记录生成B+树，存储到临时文件中；

    生成临时文件的过程中，将所有对A的操作记录在一个日志文件（row log）中，对应的是图中state2的状态；

    临时文件生成后，将日志文件中的操作应用到临时文件，得到一个逻辑数据上与表A相同的数据文件，对应的就是图中state3的状态；

    用临时文件替换表A的数据文件。

当表的数据越来越多的时候Count（*）语句越来越慢怎么办？
在不同的MySQL引擎中，count(*)有不同的实现方式
    MyISAM引擎把一个表的总行数存在了磁盘上，因此执行count(*)的时候会直接返回这个数，效率很高；
    而InnoDB引擎就麻烦了，它执行count(*)的时候，需要把数据一行一行地从引擎里面读出来，然后累积计数。
那为什么InnoDB不跟MyISAM一样，也把数字存起来呢？
    这是因为InnoDB对事务的支持即使是在同一个时刻的多个查询，由于多版本并发控制（MVCC）的原因，InnoDB表“应该返回多少行”也是不确定的。
    InnoDB是索引组织表，主键索引树的叶子节点是数据，而普通索引树的叶子节点是主键值。所以，普通索引树比主键索引树小很多。对于count(*)这样的操作，遍历哪个索引树得到的结果逻辑上都是一样的。因此，MySQL优化器会找到最小的那棵树来遍历。在保证逻辑正确的前提下，尽量减少扫描的数据量，是数据库系统设计的通用法则之一。

解决方式：目前的情况下我们只能自己进行技术：
    1：在缓存系统存放计数
        缺点：缓存丢失，更新不及时
    1：在数据库保存计数
        利用数据库事务的特性解决了更新不及时，数据不准确的问题

在select count(?) from t这样的查询语句里面，count(*)、count(主键id)、count(字段)和count(1)等不同用法的性能，有哪些差别。今天谈到了count(*)的性能问题，我就借此机会和你详细说明一下这几种用法的性能差别？
    首先你要弄清楚count()的语义。count()是一个聚合函数，对于返回的结果集，一行行地判断，如果count函数的参数不是NULL，累计值就加1，否则不加。最后返回累计值。
    所以，count(*)、count(主键id)和count(1) 都表示返回满足条件的结果集的总行数；而count(字段），则表示返回满足条件的数据行里面，参数“字段”不为NULL的总个数。

    至于分析性能差别的时候，你可以记住这么几个原则：

    server层要什么就给什么；

    InnoDB只给必要的值；

    现在的优化器只优化了count(*)的语义为“取行数”，其他“显而易见”的优化并没有做。

    这是什么意思呢？接下来，我们就一个个地来看看。

    对于count(主键id)来说，InnoDB引擎会遍历整张表，把每一行的id值都取出来，返回给server层。server层拿到id后，判断是不可能为空的，就按行累加。

    对于count(1)来说，InnoDB引擎遍历整张表，但不取值。server层对于返回的每一行，放一个数字“1”进去，判断是不可能为空的，按行累加。

    单看这两个用法的差别的话，你能对比出来，count(1)执行得要比count(主键id)快。因为从引擎返回id会涉及到解析数据行，以及拷贝字段值的操作。

    对于count(字段)来说：

    如果这个“字段”是定义为not null的话，一行行地从记录里面读出这个字段，判断不能为null，按行累加；

    如果这个“字段”定义允许为null，那么执行的时候，判断到有可能是null，还要把值取出来再判断一下，不是null才累加。

    也就是前面的第一条原则，server层要什么字段，InnoDB就返回什么字段。

    但是count(*)是例外，并不会把全部字段取出来，而是专门做了优化，不取值。count(*)肯定不是null，按行累加。

    看到这里，你一定会说，优化器就不能自己判断一下吗，主键id肯定非空啊，为什么不能按照count(*)来处理，多么简单的优化啊。

    当然，MySQL专门针对这个语句进行优化，也不是不可以。但是这种需要专门优化的情况太多了，而且MySQL已经优化过count(*)了，你直接使用这种用法就可以了。

    所以结论是：按照效率排序的话，count(字段)<count(主键id)<count(1)≈count(*)，所以我建议你，尽量使用count(*)。

Order By语句是怎么执行的？
    例如Sql：select city,name,age from t where city='杭州' order by name limit 1000  ;
    通常情况下，这个语句执行流程如下所示 ：

    初始化sort_buffer，确定放入name、city、age这三个字段；

    从索引city找到第一个满足city='杭州’条件的主键id，也就是图中的ID_X；

    到主键id索引取出整行，取name、city、age三个字段的值，存入sort_buffer中；

    从索引city取下一个记录的主键id；

    重复步骤3、4直到city的值不满足查询条件为止，对应的主键id也就是图中的ID_Y；

    对sort_buffer中的数据按照字段name做快速排序；

    按照排序结果取前1000行返回给客户端。
    如图orderBy.jpg

  rowid排序
  在上面这个算法过程里面，只对原表的数据读了一遍，剩下的操作都是在sort_buffer和临时文件中执行的。但这个算法有一个问题，就是如果查询要返回的字段很多的话，那么sort_buffer里面要放的字段数太多，这样内存里能够同时放下的行数很少，要分成很多个临时文件，排序的性能会很差。

  所以如果单行很大，这个方法效率不够好。

  那么，如果MySQL认为排序的单行长度太大会怎么做呢？

  接下来，我来修改一个参数，让MySQL采用另外一种算法。

  SET max_length_for_sort_data = 16;
  max_length_for_sort_data，是MySQL中专门控制用于排序的行数据的长度的一个参数。它的意思是，如果单行的长度超过这个值，MySQL就认为单行太大，要换一个算法。

  city、name、age 这三个字段的定义总长度是36，我把max_length_for_sort_data设置为16，我们再来看看计算过程有什么改变。

  新的算法放入sort_buffer的字段，只有要排序的列（即name字段）和主键id。

  但这时，排序的结果就因为少了city和age字段的值，不能直接返回了，整个执行流程就变成如下所示的样子：

  初始化sort_buffer，确定放入两个字段，即name和id；

  从索引city找到第一个满足city='杭州’条件的主键id，也就是图中的ID_X；

  到主键id索引取出整行，取name、id这两个字段，存入sort_buffer中；

  从索引city取下一个记录的主键id；

  重复步骤3、4直到不满足city='杭州’条件为止，也就是图中的ID_Y；

  对sort_buffer中的数据按照字段name进行排序；
  详细过程查看 rowIdSort.jpg

  遍历排序结果，取前1000行，并按照id的值回到原表中取出city、name和age三个字段返回给客户端。
按name排序”这个动作，可能在内存中完成，也可能需要使用外部排序，这取决于排序所需的内存和参数sort_buffer_size。
sort_buffer_size，就是MySQL为排序开辟的内存（sort_buffer）的大小。如果要排序的数据量小于sort_buffer_size，
排序就在内存中完成。但如果排序数据量太大，内存放不下，则不得不利用磁盘临时文件辅助排序。

另外：如果能保证索引是有序的，并且加上覆盖索引避免回表操作，期查询速度会由进一步的提高
