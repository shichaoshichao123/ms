Mysqlde WAL机制：

    mySql的InnoDB引擎通过使用redo log的方式将磁盘随机写转换成了顺序写，通过将数据更新记录缓存到内存中的数据页后直接返回操作结果，并且在redo log中记录操作
    在内存不足的时候进行刷脏页（同步操作到磁盘中）来保证执行效率。

什么是脏页：
当内存数据页跟磁盘数据页内容不一致的时候，我们称这个内存页为“脏页”。内存数据写入到磁盘后，内存和磁盘上的数据页的内容就一致了，称为“干净页”。

刷脏页的触发时机：
第一种场景是，粉板满了，记不下了。这时候如果再有人来赊账，掌柜就只得放下手里的活儿，将粉板上的记录擦掉一些，留出空位以便继续记账。当然在擦掉之前，他必须先将正确的账目记录到账本中才行。
这个场景，对应的就是InnoDB的redo log写满了。这时候系统会停止所有更新操作，把checkpoint往前推进，redo log留出空间可以继续写。我在第二讲画了一个redo log的示意图，这里我改成环形，便于大家理解。


checkpoint可不是随便往前修改一下位置就可以的。比如图2中，把checkpoint位置从CP推进到CP’，就需要将两个点之间的日志（浅绿色部分），对应的所有脏页都flush到磁盘上。之后，图中从write pos到CP’之间就是可以再写入的redo log的区域。

第二种场景是，这一天生意太好，要记住的事情太多，掌柜发现自己快记不住了，赶紧找出账本把孔乙己这笔账先加进去。
这种场景，对应的就是系统内存不足。当需要新的内存页，而内存不够用的时候，就要淘汰一些数据页，空出内存给别的数据页使用。如果淘汰的是“脏页”，就要先将脏页写到磁盘。
你一定会说，这时候难道不能直接把内存淘汰掉，下次需要请求的时候，从磁盘读入数据页，然后拿redo log出来应用不就行了？这里其实是从性能考虑的。如果刷脏页一定会写盘，就保证了每个数据页有两种状态：

一种是内存里存在，内存里就肯定是正确的结果，直接返回；
另一种是内存里没有数据，就可以肯定数据文件上是正确的结果，读入内存后返回。
这样的效率最高。
第三种场景是，生意不忙的时候，或者打烊之后。这时候柜台没事，掌柜闲着也是闲着，不如更新账本。
这种场景，对应的就是MySQL认为系统“空闲”的时候。当然，MySQL“这家酒店”的生意好起来可是会很快就能把粉板记满的，所以“掌柜”要合理地安排时间，即使是“生意好”的时候，也要见缝插针地找时间，只要有机会就刷一点“脏页”。

第四种场景是，年底了咸亨酒店要关门几天，需要把账结清一下。这时候掌柜要把所有账都记到账本上，这样过完年重新开张的时候，就能就着账本明确账目情况了。
这种场景，对应的就是MySQL正常关闭的情况。这时候，MySQL会把内存的脏页都flush到磁盘上，这样下次MySQL启动的时候，就可以直接从磁盘上读数据，启动速度会很快。

2：关于唯一索引与普通索引的选择：
    在mysql中唯一索引是不回使用到change buffer的而普通所以会使用的change buffer ，并且唯一索引在数据查询中

什么是change buffer:
    当需要更新一个数据页时，如果数据页在内存中就直接更新，而如果这个数据页还没有在内存中的话，在不影响数据一致性的前提下，InooDB会将这些更新操作缓存在change buffer中，这样就不需要从磁盘中读入这个数据页了。在下次查询需要访问这个数据页的时候，将数据页读入内存，然后执行change buffer中与这个页有关的操作。通过这种方式就能保证这个数据逻辑的正确性。
    需要说明的是，虽然名字叫作change buffer，实际上它是可以持久化的数据。也就是说，change buffer在内存中有拷贝，也会被写入到磁盘上。
    将change buffer中的操作应用到原数据页，得到最新结果的过程称为merge。除了访问这个数据页会触发merge外，系统有后台线程会定期merge。在数据库正常关闭（shutdown）的过程中，也会执行merge操作。
    显然，如果能够将更新操作先记录在change buffer，减少读磁盘，语句的执行速度会得到明显的提升。而且，数据读入内存是需要占用buffer pool的，所以这种方式还能够避免占用内存，提高内存利用率。
    如果所有的更新后面，都马上伴随着对这个记录的查询，那么你应该关闭change buffer。而在其他情况下，change buffer都能提升更新性能。
    在实际使用中，你会发现，普通索引和change buffer的配合使用，对于数据量大的表的更新优化还是很明显的。
    特别地，在使用机械硬盘时，change buffer这个机制的收效是非常显著的。所以，当你有一个类似“历史数据”的库，并且出于成本考虑用的是机械硬盘时，那你应该特别关注这些表里的索引，尽量使用普通索引，然后把change buffer 尽量开大，以确保这个“历史数据”表的数据写入速度。
    change buffer 和 redo log
    理解了change buffer的原理，你可能会联想到我在前面文章中和你介绍过的redo log和WAL。
    在前面文章的评论中，我发现有同学混淆了redo log和change buffer。WAL 提升性能的核心机制，也的确是尽量减少随机读写，这两个概念确实容易混淆。所以，这里我把它们放到了同一个流程里来说明，便于你区分这两个概念。
    总结来说：change buffer是用于优化数据库写的而redo log是尽量减少 磁盘的随机读写的。所以对于写多读少的业务使用change buffer很合适。
    所以推荐尽量使用普通索引！！！
唯一索引为什么不能使用change buffer：
    对于唯一索引来说，所有的更新操作都要先判断这个操作是否违反唯一性约束。比如，要插入(4,400)这个记录，就要先判断现在表中是否已经存在k=4的记录，而这必须要将数据页读入内存才能判断。如果都已经读入到内存了，那直接更新内存会更快，就没必要使用change buffer了。

为什么我们用Delete删除了一般的表数据，但数据表占用的空间并没有减少？

    我们知道Mysql的数据是以B+树组织的，但当我们删除某个记录时只是把某个记录占用的位置标记为可复用，当某新增的记录刚要落在这个位置就可以直接覆盖，我们知道Mysql的数据是分页存储的，当整个页里面的数据都被标记删除那整个页都可以被复用，
    所以真正的原理是虽然表面删了但实际上占的空间没有被释放只是被标记为可复用标记。
    同时我们在进行插入操作的时候也有可能会内存空洞（尤其是在主键索引不连续（不紧凑）的情况）会造成页分裂。
    解决方式：重建表,使用alter table t engine=InnoDB;不过表数据打的时候要注意系统的磁盘IO压力

在MySQL 5.6版本开始引入的Online DDL，对这个操作流程做了优化。

简单描述一下引入了Online DDL之后，重建表的流程：

    建立一个临时文件，扫描表A主键的所有数据页；

    用数据页中表A的记录生成B+树，存储到临时文件中；

    生成临时文件的过程中，将所有对A的操作记录在一个日志文件（row log）中，对应的是图中state2的状态；

    临时文件生成后，将日志文件中的操作应用到临时文件，得到一个逻辑数据上与表A相同的数据文件，对应的就是图中state3的状态；

    用临时文件替换表A的数据文件。

当表的数据越来越多的时候Count（*）语句越来越慢怎么办？
在不同的MySQL引擎中，count(*)有不同的实现方式
    MyISAM引擎把一个表的总行数存在了磁盘上，因此执行count(*)的时候会直接返回这个数，效率很高；
    而InnoDB引擎就麻烦了，它执行count(*)的时候，需要把数据一行一行地从引擎里面读出来，然后累积计数。
那为什么InnoDB不跟MyISAM一样，也把数字存起来呢？
    这是因为InnoDB对事务的支持即使是在同一个时刻的多个查询，由于多版本并发控制（MVCC）的原因，InnoDB表“应该返回多少行”也是不确定的。
    InnoDB是索引组织表，主键索引树的叶子节点是数据，而普通索引树的叶子节点是主键值。所以，普通索引树比主键索引树小很多。对于count(*)这样的操作，遍历哪个索引树得到的结果逻辑上都是一样的。因此，MySQL优化器会找到最小的那棵树来遍历。在保证逻辑正确的前提下，尽量减少扫描的数据量，是数据库系统设计的通用法则之一。

解决方式：目前的情况下我们只能自己进行技术：
    1：在缓存系统存放计数
        缺点：缓存丢失，更新不及时
    1：在数据库保存计数
        利用数据库事务的特性解决了更新不及时，数据不准确的问题

在select count(?) from t这样的查询语句里面，count(*)、count(主键id)、count(字段)和count(1)等不同用法的性能，有哪些差别。今天谈到了count(*)的性能问题，我就借此机会和你详细说明一下这几种用法的性能差别？
    首先你要弄清楚count()的语义。count()是一个聚合函数，对于返回的结果集，一行行地判断，如果count函数的参数不是NULL，累计值就加1，否则不加。最后返回累计值。
    所以，count(*)、count(主键id)和count(1) 都表示返回满足条件的结果集的总行数；而count(字段），则表示返回满足条件的数据行里面，参数“字段”不为NULL的总个数。

    至于分析性能差别的时候，你可以记住这么几个原则：

    server层要什么就给什么；

    InnoDB只给必要的值；

    现在的优化器只优化了count(*)的语义为“取行数”，其他“显而易见”的优化并没有做。

    这是什么意思呢？接下来，我们就一个个地来看看。

    对于count(主键id)来说，InnoDB引擎会遍历整张表，把每一行的id值都取出来，返回给server层。server层拿到id后，判断是不可能为空的，就按行累加。

    对于count(1)来说，InnoDB引擎遍历整张表，但不取值。server层对于返回的每一行，放一个数字“1”进去，判断是不可能为空的，按行累加。

    单看这两个用法的差别的话，你能对比出来，count(1)执行得要比count(主键id)快。因为从引擎返回id会涉及到解析数据行，以及拷贝字段值的操作。

    对于count(字段)来说：

    如果这个“字段”是定义为not null的话，一行行地从记录里面读出这个字段，判断不能为null，按行累加；

    如果这个“字段”定义允许为null，那么执行的时候，判断到有可能是null，还要把值取出来再判断一下，不是null才累加。

    也就是前面的第一条原则，server层要什么字段，InnoDB就返回什么字段。

    但是count(*)是例外，并不会把全部字段取出来，而是专门做了优化，不取值。count(*)肯定不是null，按行累加。

    看到这里，你一定会说，优化器就不能自己判断一下吗，主键id肯定非空啊，为什么不能按照count(*)来处理，多么简单的优化啊。

    当然，MySQL专门针对这个语句进行优化，也不是不可以。但是这种需要专门优化的情况太多了，而且MySQL已经优化过count(*)了，你直接使用这种用法就可以了。

    所以结论是：按照效率排序的话，count(字段)<count(主键id)<count(1)≈count(*)，所以我建议你，尽量使用count(*)。

Order By语句是怎么执行的？
    例如Sql：select city,name,age from t where city='杭州' order by name limit 1000  ;
    通常情况下，这个语句执行流程如下所示 ：

    初始化sort_buffer，确定放入name、city、age这三个字段；

    从索引city找到第一个满足city='杭州’条件的主键id，也就是图中的ID_X；

    到主键id索引取出整行，取name、city、age三个字段的值，存入sort_buffer中；

    从索引city取下一个记录的主键id；

    重复步骤3、4直到city的值不满足查询条件为止，对应的主键id也就是图中的ID_Y；

    对sort_buffer中的数据按照字段name做快速排序；

    按照排序结果取前1000行返回给客户端。
    如图orderBy.jpg

  rowid排序
  在上面这个算法过程里面，只对原表的数据读了一遍，剩下的操作都是在sort_buffer和临时文件中执行的。但这个算法有一个问题，就是如果查询要返回的字段很多的话，那么sort_buffer里面要放的字段数太多，这样内存里能够同时放下的行数很少，要分成很多个临时文件，排序的性能会很差。

  所以如果单行很大，这个方法效率不够好。

  那么，如果MySQL认为排序的单行长度太大会怎么做呢？

  接下来，我来修改一个参数，让MySQL采用另外一种算法。

  SET max_length_for_sort_data = 16;
  max_length_for_sort_data，是MySQL中专门控制用于排序的行数据的长度的一个参数。它的意思是，如果单行的长度超过这个值，MySQL就认为单行太大，要换一个算法。

  city、name、age 这三个字段的定义总长度是36，我把max_length_for_sort_data设置为16，我们再来看看计算过程有什么改变。

  新的算法放入sort_buffer的字段，只有要排序的列（即name字段）和主键id。

  但这时，排序的结果就因为少了city和age字段的值，不能直接返回了，整个执行流程就变成如下所示的样子：

  初始化sort_buffer，确定放入两个字段，即name和id；

  从索引city找到第一个满足city='杭州’条件的主键id，也就是图中的ID_X；

  到主键id索引取出整行，取name、id这两个字段，存入sort_buffer中；

  从索引city取下一个记录的主键id；

  重复步骤3、4直到不满足city='杭州’条件为止，也就是图中的ID_Y；

  对sort_buffer中的数据按照字段name进行排序；
  详细过程查看 rowIdSort.jpg

  遍历排序结果，取前1000行，并按照id的值回到原表中取出city、name和age三个字段返回给客户端。
按name排序”这个动作，可能在内存中完成，也可能需要使用外部排序，这取决于排序所需的内存和参数sort_buffer_size。
sort_buffer_size，就是MySQL为排序开辟的内存（sort_buffer）的大小。如果要排序的数据量小于sort_buffer_size，
排序就在内存中完成。但如果排序数据量太大，内存放不下，则不得不利用磁盘临时文件辅助排序。

另外：如果能保证索引是有序的，并且加上覆盖索引避免回表操作，期查询速度会由进一步的提高

导致单条记录查询一直不返回的原因：
    1：等待表的MDL锁，也就是该锁被其它线程占有着
    2：等待表的Flush完成，在表进行Flush的时候会关闭指定的表，但Flush过程一般很短所以长时间不反悔很有可能是有别的线程阻塞改了Flush线程。导致的传递等待
    3：等待行锁，有其他线程持有了这一行的写锁，所以就需要等待对应的线程释放行锁

导致单条记录查询慢的原因：
    1：select * from t where id=1；（一致性读）
    2：select * from t where id=1 lock in share mode；（当前读）
   在某些情况下会出现语句一的查询速度比语句二慢很多，复现场景是如果查询期间又有一个Session对指定的id记录进行了数百万次更新操作，原因在于语句一是一致性读，带lock in share mode的SQL语句，是当前读，因此会直接读到1000001这个结果，所以速度很快；而select * from t where id=1这个语句，是一致性读，因此需要从1000001开始，依次执行undo log，执行了100万次以后，才将1这个结果返回。

何为幻读：
    session A里执行了三次查询，分别是Q1、Q2和Q3。它们的SQL语句相同，都是select * from t where d=5 for update。这个语句的意思你应该很清楚了，查所有d=5的行，而且使用的是当前读，并且加上写锁。现在，我们来看一下这三条SQL语句，分别会返回什么结果。
    Q1只返回id=5这一行；
    在T2时刻，session B把id=0这一行的d值改成了5，因此T3时刻Q2查出来的是id=0和id=5这两行；
    在T4时刻，session C又插入一行（1,1,5），因此T5时刻Q3查出来的是id=0、id=1和id=5的这三行。
    其中，Q3读到id=1这一行的现象，被称为“幻读”。也就是说，幻读指的是一个事务在前后两次查询同一个范围的时候，后一次查询看到了前一次查询没有看到的行。
    这里，我需要对“幻读”做一个说明：
    在可重复读隔离级别下，普通的查询是快照读，是不会看到别的事务插入的数据的。因此，幻读在“当前读”下才会出现。
    上面session B的修改结果，被session A之后的select语句用“当前读”看到，不能称为幻读。幻读仅专指“新插入的行”。
    如果只从第8篇文章《事务到底是隔离的还是不隔离的？》我们学到的事务可见性规则来分析的话，上面这三条SQL语句的返回结果都没有问题。
    因为这三个查询都是加了for update，都是当前读。而当前读的规则，就是要能读到所有已经提交的记录的最新值。并且，session B和sessionC的两条语句，执行后就会提交，所以Q2和Q3就是应该看到这两个事务的操作效果，而且也看到了，这跟事务的可见性规则并不矛盾。

 如何解决幻读？
    现在你知道了，产生幻读的原因是，行锁只能锁住行，但是新插入记录这个动作，要更新的是记录之间的“间隙”。因此，为了解决幻读问题，InnoDB只好引入新的锁，也就是间隙锁(Gap Lock)。
  next-key lock：行锁和间隙锁组成的
  加next-key lock(5,10] ”操作，实际上分成了两步，先是加(5,10)的间隙锁，加锁成功；然后加c=10的行锁。间隙锁之间是不会相互影响的
   注意：间隙锁在可重复读下才有效。


MySql加锁规则：
    1：MySQL后面的版本可能会改变加锁策略，所以这个规则只限于截止到现在的最新版本，即5.x系列<=5.7.24，8.0系列 <=8.0.13。
    2：如果大家在验证中有发现bad case的话，请提出来，我会再补充进这篇文章，使得一起学习本专栏的所有同学都能受益
原则1：加锁的基本单位是next-key lock。希望你还记得，next-key lock是前开后闭区间。

原则2：查找过程中访问到的对象才会加锁。

优化1：索引上的等值查询，给唯一索引加锁的时候，next-key lock退化为行锁。

优化2：索引上的等值查询，向右遍历时且最后一个值不满足等值条件的时候，next-key lock退化为间隙锁。

一个bug：唯一索引上的范围查询会访问到不满足条件的第一个值为止。

结论：1：在删除数据的时候尽量加limit。这样不仅可以控制删除数据的条数，让操作更安全，还可以减小加锁的范围。

慢查询性能问题
在MySQL中，会引发性能问题的慢查询，大体有以下三种可能：

    索引没有设计好；

    SQL语句没写好；

    MySQL选错了索引。

导致慢查询的第一种可能是，索引没有设计好。

    这种场景一般就是通过紧急创建索引来解决。MySQL 5.6版本以后，创建索引都支持Online DDL了，对于那种高峰期数据库已经被这个语句打挂了的情况，最高效的做法就是直接执行alter table 语句。
    比较理想的是能够在备库先执行。假设你现在的服务是一主一备，主库A、备库B，这个方案的大致流程是这样的：
    在备库B上执行 set sql_log_bin=off，也就是不写binlog，然后执行alter table 语句加上索引；
    执行主备切换；
    这时候主库是B，备库是A。在A上执行 set sql_log_bin=off，然后执行alter table 语句加上索引。
    这是一个“古老”的DDL方案。平时在做变更的时候，你应该考虑类似gh-ost这样的方案，更加稳妥。但是在需要紧急处理时，上面这个方案的效率是最高的。

导致慢查询的第二种可能是，语句没写好。

    比如，我们犯了在第18篇文章《为什么这些SQL语句逻辑相同，性能却差异巨大？》中提到的那些错误，导致语句没有使用上索引。
    这时，我们可以通过改写SQL语句来处理。MySQL 5.7提供了query_rewrite功能，可以把输入的一种语句改写成另外一种模式。
    比如，语句被错误地写成了 select * from t where id + 1 = 10000，你可以通过下面的方式，增加一个语句改写规则。

导致慢查询的第三种可能，就是碰上了我们在第10篇文章《MySQL为什么有时候会选错索引？》中提到的情况，MySQL选错了索引。

    这时候，应急方案就是给这个语句加上force index。
    同样地，使用查询重写功能，给原来的语句加上force index，也可以解决这个问题。

通过下面这个过程，我们就可以预先发现问题。

    上线前，在测试环境，把慢查询日志（slow log）打开，并且把long_query_time设置成0，确保每个语句都会被记录入慢查询日志；
    在测试表里插入模拟线上的数据，做一遍回归测试；
    观察慢查询日志里每类语句的输出，特别留意Rows_examined字段是否与预期一致。（我们在前面文章中已经多次用到过Rows_examined方法了，相信你已经动手尝试过了。如果还有不明白的，欢迎给我留言，我们一起讨论）。
    不要吝啬这段花在上线前的“额外”时间，因为这会帮你省下很多故障复盘的时间。

QPS突增问题
    有时候由于业务突然出现高峰，或者应用程序bug，导致某个语句的QPS突然暴涨，也可能导致MySQL压力过大，影响服务。

    我之前碰到过一类情况，是由一个新功能的bug导致的。当然，最理想的情况是让业务把这个功能下掉，服务自然就会恢复。

    而下掉一个功能，如果从数据库端处理的话，对应于不同的背景，有不同的方法可用。我这里再和你展开说明一下。

    一种是由全新业务的bug导致的。假设你的DB运维是比较规范的，也就是说白名单是一个个加的。这种情况下，如果你能够确定业务方会下掉这个功能，只是时间上没那么快，那么就可以从数据库端直接把白名单去掉。

    如果这个新功能使用的是单独的数据库用户，可以用管理员账号把这个用户删掉，然后断开现有连接。这样，这个新功能的连接不成功，由它引发的QPS就会变成0。

    如果这个新增的功能跟主体功能是部署在一起的，那么我们只能通过处理语句来限制。这时，我们可以使用上面提到的查询重写功能，把压力最大的SQL语句直接重写成"select 1"返回。

    当然，这个操作的风险很高，需要你特别细致。它可能存在两个副作用：

    如果别的功能里面也用到了这个SQL语句模板，会有误伤；

    很多业务并不是靠这一个语句就能完成逻辑的，所以如果单独把这一个语句以select 1的结果返回的话，可能会导致后面的业务逻辑一起失败。

    所以，方案3是用于止血的，跟前面提到的去掉权限验证一样，应该是你所有选项里优先级最低的一个方案。

    同时你会发现，其实方案1和2都要依赖于规范的运维体系：虚拟化、白名单机制、业务账号分离。由此可见，更多的准备，往往意味着更稳定的系统。

MySql是怎么保证数据不丢失的？

1：binlog的写入机制
    其实，binlog的写入逻辑比较简单：事务执行过程中，先把日志写到binlog cache，事务提交的时候，再把binlog cache写到binlog文件中。
    一个事务的binlog是不能被拆开的，因此不论这个事务多大，也要确保一次性写入。这就涉及到了binlog cache的保存问题。
    系统给binlog cache分配了一片内存，每个线程一个，参数 binlog_cache_size用于控制单个线程内binlog cache所占内存的大小。如果超过了这个参数规定的大小，就要暂存到磁盘。
    事务提交的时候，执行器把binlog cache里的完整事务写入到binlog中，并清空binlog cache

2：redo log的写入机制
    接下来，我们再说说redo log的写入机制。
    在专栏的第15篇答疑文章中，我给你介绍了redo log buffer。事务在执行过程中，生成的redo log是要先写到redo log buffer的。
    然后就有同学问了，redo log buffer里面的内容，是不是每次生成后都要直接持久化到磁盘呢？
    答案是，不需要。
    如果事务执行期间MySQL发生异常重启，那这部分日志就丢了。由于事务并没有提交，所以这时日志丢了也不会有损失。
    那么，另外一个问题是，事务还没提交的时候，redo log buffer中的部分日志有没有可能被持久化到磁盘呢？
    答案是，确实会有。
如果你的MySQL现在出现了性能瓶颈，而且瓶颈在IO上，可以通过哪些方法来提升性能呢？
    针对这个问题，可以考虑以下三种方法：
    设置 binlog_group_commit_sync_delay 和 binlog_group_commit_sync_no_delay_count参数，减少binlog的写盘次数。这个方法是基于“额外的故意等待”来实现的，因此可能会增加语句的响应时间，但没有丢失数据的风险。
    将sync_binlog 设置为大于1的值（比较常见是100~1000）。这样做的风险是，主机掉电时会丢binlog日志。
    将innodb_flush_log_at_trx_commit设置为2。这样做的风险是，主机掉电的时候会丢数据。

MySql主备是如何保持一致的？

    看图 slave.jpg
    1：备库B跟主库A之间维持了一个长连接。主库A内部有一个线程，专门用于服务备库B的这个长连接。一个事务日志同步的完整过程是这样的：
    2：在备库B上通过change master命令，设置主库A的IP、端口、用户名、密码，以及要从哪个位置开始请求binlog，这个位置包含文件名和日志偏移量。
    3：在备库B上执行start slave命令，这时候备库会启动两个线程，就是图中的io_thread和sql_thread。其中io_thread负责与主库建立连接。
    4：主库A校验完用户名、密码后，开始按照备库B传过来的位置，从本地读取binlog，发给B。
    5：备库B拿到binlog后，写到本地文件，称为中转日志（relay log）。
    6：sql_thread读取中转日志，解析出日志里的命令，并执行。
    tip:这里需要说明，后来由于多线程复制方案的引入，sql_thread演化成为了多个线程，跟我们今天要介绍的原理没有直接关系，暂且不展开。

binlog的三种格式对比
    binlog有两种格式，一种是statement，一种是row。可能你在其他资料上还会看到有第三种格式，叫作mixed，其实它就是前两种格式的混合。
    1:当binlog_format=statement时，binlog里面记录的就是SQL语句的原文
    2:row格式的binlog里没有了SQL语句的原文，而是替换成了两个event：Table_map和Delete_rows
    3:为什么会有mixed格式的binlog？
      基于上面的信息，我们来讨论一个问题：为什么会有mixed这种binlog格式的存在场景？推论过程是这样的：
      因为有些statement格式的binlog可能会导致主备不一致，所以要使用row格式。
      但row格式的缺点是，很占空间。比如你用一个delete语句删掉10万行数据，用statement的话就是一个SQL语句被记录到binlog中，占用几十个字节的空间。但如果用row格式的binlog，就要把这10万条记录都写到binlog中。这样做，不仅会占用更大的空间，同时写binlog也要耗费IO资源，影响执行速度。
      所以，MySQL就取了个折中方案，也就是有了mixed格式的binlog。mixed格式的意思是，MySQL自己会判断这条SQL语句是否可能引起主备不一致，如果有可能，就用row格式，否则就用statement格式。
      也就是说，mixed格式可以利用statment格式的优点，同时又避免了数据不一致的风险。
      因此，如果你的线上MySQL设置的binlog格式是statement的话，那基本上就可以认为这是一个不合理的设置。你至少应该把binlog的格式设置为mixed。
      比如我们这个例子，设置为mixed后，就会记录为row格式；而如果执行的语句去掉limit 1，就会记录为statement格式。
      当然我要说的是，现在越来越多的场景要求把MySQL的binlog格式设置成row。这么做的理由有很多，我来给你举一个可以直接看出来的好处：恢复数据。

MySql的Innodb引擎下执行一条更新语句的流程：
    1：在内存中生成undo log
    2：根据WAL机制更新内存中的数据
    3：redo log 进入prepare阶段
    4：提交事务 开始写binlog 并持久化到磁盘
    5：redo log 提交并持久化到磁盘

JOIN语句使用的问题：

    前提：这个结论的前提是“可以使用被驱动表的索引”。
    Index Nested-Loop Join
    1：根据执行join语句以及分开单表查询获取的数据两者扫描记录数量的多少来判断，有的时候Join会比单表查询效率高。
    2：选对驱动表：
        我们再来看看第二个问题：怎么选择驱动表？
        在这个join语句执行过程中，驱动表是走全表扫描，而被驱动表是走树搜索。
        假设被驱动表的行数是M。每次在被驱动表查一行数据，要先搜索索引a，再搜索主键索引。每次搜索一棵树近似复杂度是以2为底的M的对数，记为log2M，所以在被驱动表上查一行的时间复杂度是 2*log2M。
        假设驱动表的行数是N，执行过程就要扫描驱动表N行，然后对于每一行，到被驱动表上匹配一次。
        因此整个执行过程，近似复杂度是 N + N*2*log2M。
        显然，N对扫描行数的影响更大，因此应该让小表来做驱动表。

    前提：在没有可用的索引的情况下：
    Simple Nested-Loop Join：
        由于表t2的字段b上没有索引，因此再用图2的执行流程时，每次到t2去匹配的时候，就要做一次全表扫描。
        你可以先设想一下这个问题，继续使用图2的算法，是不是可以得到正确的结果呢？如果只看结果的话，这个算法是正确的，而且这个算法也有一个名字，叫做“Simple Nested-Loop Join”。
        但是，这样算来，这个SQL请求就要扫描表t2多达100次，总共扫描100*1000=10万行。
        这还只是两个小表，如果t1和t2都是10万行的表（当然了，这也还是属于小表的范围），就要扫描100亿行，这个算法看上去太“笨重”了。

    Block Nested-Loop Join（扫描次数差不多不过这是在内存里比较所以速度更快）：
    把表t1的数据读入线程内存join_buffer中，由于我们这个语句中写的是select *，因此是把整个表t1放入了内存；
    扫描表t2，把表t2中的每一行取出来，跟join_buffer中的数据做对比，满足join条件的，作为结果集的一部分返回。

    你可能马上就会问了，这个例子里表t1才100行，要是表t1是一个大表，join_buffer放不下怎么办呢？
    执行过程就变成了：
    1：扫描表t1，顺序读取数据行放入join_buffer中，放完第88行join_buffer满了，继续第2步；
    2：扫描表t2，把t2中的每一行取出来，跟join_buffer中的数据做对比，满足join条件的，作为结果集的一部分返回；
    3：清空join_buffer；
    4：继续扫描表t1，顺序读取最后的12行数据放入join_buffer中，继续执行第2步。
    如果你的join语句很慢，就把join_buffer_size改大。
    总结：总体来说用小表做驱动表还是更好一些。

第一个问题：能不能使用join语句？

    如果可以使用Index Nested-Loop Join算法，也就是说可以用上被驱动表上的索引，其实是没问题的；
    如果使用Block Nested-Loop Join算法，扫描行数就会过多。尤其是在大表上的join操作，这样可能要扫描被驱动表很多次，会占用大量的系统资源。所以这种join尽量不要用。
    所以你在判断要不要使用join语句时，就是看explain结果里面，Extra字段里面有没有出现“Block Nested Loop”字样。

第二个问题是：如果要使用join，应该选择大表做驱动表还是选择小表做驱动表？

    如果是Index Nested-Loop Join算法，应该选择小表做驱动表；
    如果是Block Nested-Loop Join算法：
    在join_buffer_size足够大的时候，是一样的；
    在join_buffer_size不够大的时候（这种情况更常见），应该选择小表做驱动表。
    所以，这个问题的结论就是，总是应该使用小表做驱动表。

当然了，这里我需要说明下，什么叫作“小表”。

    我们前面的例子是没有加条件的。如果我在语句的where条件加上 t2.id<=50这个限定条件，再来看下这两条语句：
    select * from t1 straight_join t2 on (t1.b=t2.b) where t2.id<=50;
    select * from t2 straight_join t1 on (t1.b=t2.b) where t2.id<=50;
    注意，为了让两条语句的被驱动表都用不上索引，所以join字段都使用了没有索引的字段b。
    但如果是用第二个语句的话，join_buffer只需要放入t2的前50行，显然是更好的。所以这里，“t2的前50行”是那个相对小的表，也就是“小表”。

    我们再来看另外一组例子：
    select t1.b,t2.* from  t1  straight_join t2 on (t1.b=t2.b) where t2.id<=100;
    select t1.b,t2.* from  t2  straight_join t1 on (t1.b=t2.b) where t2.id<=100;
    这个例子里，表t1 和 t2都是只有100行参加join。但是，这两条语句每次查询放入join_buffer中的数据是不一样的：

    表t1只查字段b，因此如果把t1放到join_buffer中，则join_buffer中只需要放入b的值；
    表t2需要查所有的字段，因此如果把表t2放到join_buffer中的话，就需要放入三个字段id、a和b。
    这里，我们应该选择表t1作为驱动表。也就是说在这个例子里，“只需要一列参与join的表t1”是那个相对小的表。
    所以，更准确地说，在决定哪个表做驱动表的时候，应该是两个表按照各自的条件过滤，过滤完成之后，计算参与join的各个字段的总数据量，数据量小的那个表，就是“小表”，应该作为驱动表

下面讲一下JOIN语句怎么优化：

    因为大多数的数据都是按照主键递增顺序插入得到的，所以我们可以认为，如果按照主键的递增顺序查询的话，对磁盘的读比较接近顺序读，能够提升读性能。

    这，就是MRR优化的设计思路。此时，语句的执行流程变成了这样：

    根据索引a，定位到满足条件的记录，将id值放入read_rnd_buffer中;

    将read_rnd_buffer中的id进行递增排序；

    排序后的id数组，依次到主键id索引中查记录，并作为结果返回。
    MRR能够提升性能的核心在于，这条查询语句在索引a上做的是一个范围查询（也就是说，这是一个多值查询），可以得到足够多的主键id。这样通过排序以后，再去主键索引查数据，才能体现出“顺序性”的优势。

BNL算法转BKA算法优化（在被驱动表（大表）使用的字段加索引）
explain结果里Extra字段显示使用了BNL算法。在我的测试环境里，这条语句需要执行1分11秒。

    在表t2的字段b上创建索引会浪费资源，但是不创建索引的话这个语句的等值条件要判断10亿次，想想也是浪费。那么，有没有两全其美的办法呢？

    这时候，我们可以考虑使用临时表。使用临时表的大致思路是：

    把表t2中满足条件的数据放在临时表tmp_t中；

    为了让join使用BKA算法，给临时表tmp_t的字段b加上索引；

    让表t1和tmp_t做join操作

扩展-hash join
看到这里你可能发现了，其实上面计算10亿次那个操作，看上去有点儿傻。如果join_buffer里面维护的不是一个无序数组，而是一个哈希表的话，那么就不是10亿次判断，而是100万次hash查找。这样的话，整条语句的执行速度就快多了吧？
    确实如此。这，也正是MySQL的优化器和执行器一直被诟病的一个原因：不支持哈希join。并且，MySQL官方的roadmap，也是迟迟没有把这个优化排上议程。

    实际上，这个优化思路，我们可以自己实现在业务端。实现流程大致如下：

    1：select * from t1;取得表t1的全部1000行数据，在业务端存入一个hash结构，比如C++里的set、PHP的dict这样的数据结构。

    2：select * from t2 where b>=1 and b<=2000; 获取表t2中满足条件的2000行数据。

    3：把这2000行数据，一行一行地取到业务端，到hash结构的数据表中寻找匹配的数据。满足匹配的条件的这行数据，就作为结果集的一行。


问题：为什么零时表可以重命名？
    临时表在使用上有以下几个特点：

        建表语法是create temporary table …。

        一个临时表只能被创建它的session访问，对其他线程不可见。所以，图中session A创建的临时表t，对于session B就是不可见的。

        临时表可以与普通表同名。

        session A内有同名的临时表和普通表的时候，show create语句，以及增删改查语句访问的是临时表。

        show tables命令不显示临时表。

        由于临时表只能被创建它的session访问，所以在这个session结束的时候，会自动删除临时表。也正是由于这个特性，临时表就特别适合我们文章开头的join优化这种场景。为什么呢？

    原因主要包括以下两个方面：

        不同session的临时表是可以重名的，如果有多个session同时执行join优化，不需要担心表名重复导致建表失败的问题。

        不需要担心数据删除问题。如果使用普通表，在流程执行过程中客户端发生了异常断开，或者数据库发生异常重启，还需要专门来清理中间过程中生成的数据表。而临时表由于会自动回收，所以不需要这个额外的操作。

由于不用担心线程之间的重名冲突，临时表经常会被用在复杂查询的优化过程中。其中，分库分表系统的跨库查询就是一个典型的使用场景。

为什么临时表可以重名？
    你可能会问，不同线程可以创建同名的临时表，这是怎么做到的呢？
    接下来，我们就看一下这个问题。
    我们在执行

    create temporary table temp_t(id int primary key)engine=innodb;
    这个语句的时候，MySQL要给这个InnoDB表创建一个frm文件保存表结构定义，还要有地方保存表数据。

    这个frm文件放在临时文件目录下，文件名的后缀是.frm，前缀是“#sql{进程id}_{线程id}_序列号”。你可以使用select @@tmpdir命令，来显示实例的临时文件目录。

    而关于表中数据的存放方式，在不同的MySQL版本中有着不同的处理方式：

    在5.6以及之前的版本里，MySQL会在临时文件目录下创建一个相同前缀、以.ibd为后缀的文件，用来存放数据文件；
    而从 5.7版本开始，MySQL引入了一个临时文件表空间，专门用来存放临时文件的数据。因此，我们就不需要再创建ibd文件了。
    从文件名的前缀规则，我们可以看到，其实创建一个叫作t1的InnoDB临时表，MySQL在存储上认为我们创建的表名跟普通表t1是不同的，因此同一个库下面已经有普通表t1的情况下，还是可以再创建一个临时表t1的。
MySQL维护数据表，除了物理上要有文件外，内存里面也有一套机制区别不同的表，每个表都对应一个table_def_key。

   一个普通表的table_def_key的值是由“库名+表名”得到的，所以如果你要在同一个库下创建两个同名的普通表，创建第二个表的过程中就会发现table_def_key已经存在了。
   而对于临时表，table_def_key在“库名+表名”基础上，又加入了“server_id+thread_id”。
   也就是说，session A和sessionB创建的两个临时表t1，它们的table_def_key不同，磁盘文件名也不同，因此可以并存。
在实现上，每个线程都维护了自己的临时表链表。这样每次session内操作表的时候，先遍历链表，检查是否有这个名字的临时表，如果有就优先操作临时表，如果没有再操作普通表；在session结束的时候，对链表里的每个临时表，执行 “DROP TEMPORARY TABLE +表名”操作。

这时候你会发现，binlog中也记录了DROP TEMPORARY TABLE这条命令。你一定会觉得奇怪，临时表只在线程内自己可以访问，为什么需要写到binlog里面？
这，就需要说到主备复制了。

MySQL在记录binlog的时候，不论是create table还是alter table语句，都是原样记录，甚至于连空格都不变。但是如果执行drop table t_normal，系统记录binlog就会写成：

DROP TABLE `t_normal` /* generated by server */
也就是改成了标准的格式。为什么要这么做呢 ？

现在你知道原因了，那就是：drop table命令是可以一次删除多个表的。比如，在上面的例子中，设置binlog_format=row，如果主库上执行 "drop table t_normal, temp_t"这个命令，那么binlog中就只能记录：

DROP TABLE `t_normal` /* generated by server */
因为备库上并没有表temp_t，将这个命令重写后再传到备库执行，才不会导致备库同步线程停止。
所以，drop table命令记录binlog的时候，就必须对语句做改写。“/* generated by server */”说明了这是一个被服务端改写过的命令。

sort buffer、内存临时表和join buffer。这三个数据结构都是用来存放语句执行过程中的中间数据，以辅助SQL语句的执行的。其中，我们在排序的时候用到了sort buffer，在使用join语句的时候用到了join buffer。

group by 优化方法 --索引
group by优化方法 --直接排序

MySQL什么时候会使用内部临时表？

    如果语句执行过程可以一边读数据，一边直接得到结果，是不需要额外内存的，否则就需要额外的内存，来保存中间结果；

    join_buffer是无序数组，sort_buffer是有序数组，临时表是二维表结构；

    如果执行逻辑需要用到二维表特性，就会优先考虑使用临时表。比如我们的例子中，union需要用到唯一索引约束， group by还需要用到另外一个字段来存累积计数。

通过今天这篇文章，我重点和你讲了group by的几种实现算法，从中可以总结一些使用的指导原则：

    如果对group by语句的结果没有排序要求，要在语句后面加 order by null；
    尽量让group by过程用上表的索引，确认方法是explain结果里没有Using temporary 和 Using filesort；
    如果group by需要统计的数据量不大，尽量只使用内存临时表；也可以通过适当调大tmp_table_size参数，来避免用到磁盘临时表；
    如果数据量实在太大，使用SQL_BIG_RESULT这个提示，来告诉优化器直接使用排序算法得到group by的结果。

内存表支持hash索引，对大查询有优势，但内存表支支持表锁不支持行锁，那样对于系统的并发能力是一个瓶颈，很有可能一个更新就会阻塞对这个表的查询
而且在数据持久化上也有问题，所以还是推荐使用InnoDB为表的数据引擎


自增主键为什么不是连续的?
    引子：之前我见过有的业务设计依赖于自增主键的连续性，也就是说，这个设计假设自增主键是连续的。但实际上，这样的假设是错的，因为自增主键不能保证连续递增

 注意：表的结构定义存放在后缀名为.frm的文件中，但是并不会保存自增值。
 MyISAM引擎的自增值保存在数据文件中。
 InnoDB引擎的自增值，其实是保存在了内存里，并且到了MySQL 8.0版本后，才有了“自增值持久化”的能力，也就是才实现了“如果发生重启，表的自增值可以恢复为MySQL重启前的值”，具体情况是：
    在MySQL 5.7及之前的版本，自增值保存在内存里，并没有持久化。每次重启后，第一次打开表的时候，都会去找自增值的最大值max(id)，然后将max(id)+1作为这个表当前的自增值。﻿
    举例来说，如果一个表当前数据行里最大的id是10，AUTO_INCREMENT=11。这时候，我们删除id=10的行，AUTO_INCREMENT还是11。但如果马上重启实例，重启后这个表的AUTO_INCREMENT就会变成10。﻿
    也就是说，MySQL重启可能会修改一个表的AUTO_INCREMENT的值。
    在MySQL 8.0版本，将自增值的变更记录在了redo log中，重启的时候依靠redo log恢复重启之前的值。

